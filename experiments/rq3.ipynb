{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time_handler(date_time_str):\n",
    "    return datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.join(\"..\",\"data\")\n",
    "developer_data = pd.read_csv(os.path.join(basedir, 'contributor_features.csv'), index_col = 0)\n",
    "filtered_developer_period_df = pd.read_csv(os.path.join(basedir,'contributor_period_activity.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.join(os.getcwd(), '..','data')\n",
    "proj_names = ['tensorflow_tensorflow',\n",
    "              'pytorch_pytorch',\n",
    "                'scikit-learn_scikit-learn',\n",
    "                'keras-team_keras',\n",
    "                'apache_mxnet',\n",
    "                'theano_aesara',\n",
    "                'onnx_onnx',\n",
    "                'deeplearning4j_deeplearning4j']\n",
    "\n",
    "repo_dirs = [os.path.join(basedir,item) for item in proj_names]\n",
    "projects = ['tensorflow', 'pytorch', 'scikit-learn', 'keras', 'mxnet', 'theano_aesara', 'onnx', 'deeplearning4j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# studied period\n",
    "start = datetime.datetime(2008,1,1)\n",
    "end = datetime.datetime(2024,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read project fork history\n",
    "project_fork_df = []\n",
    "for path in repo_dirs:\n",
    "    fork_df = pd.read_csv(os.path.join(path, 'fork_history.csv'), index_col=0)\n",
    "    fork_df['time'] = fork_df['time'].apply(lambda x:date_time_handler(x.replace('+00:00','')))\n",
    "    fork_df = fork_df.loc[(fork_df['time']>=start)&(fork_df['time']<end)]\n",
    "    project_fork_df.append(fork_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2015-11-09T13:17:30Z' does not match format '%Y-%m-%d %H:%M:%S'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m stargazer_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstar_history.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#stargazer_df['starredAt'] = stargazer_df['starredAt'].apply(lambda x:datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ'))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m stargazer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarredAt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mstargazer_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstarredAt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m stargazer_df \u001b[38;5;241m=\u001b[39m stargazer_df\u001b[38;5;241m.\u001b[39mloc[(stargazer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarredAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mstart)\u001b[38;5;241m&\u001b[39m(stargazer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarredAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m<\u001b[39mend)]\n\u001b[1;32m      8\u001b[0m project_star_df\u001b[38;5;241m.\u001b[39mappend(stargazer_df)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m stargazer_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstar_history.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#stargazer_df['starredAt'] = stargazer_df['starredAt'].apply(lambda x:datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ'))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m stargazer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarredAt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stargazer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarredAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m stargazer_df \u001b[38;5;241m=\u001b[39m stargazer_df\u001b[38;5;241m.\u001b[39mloc[(stargazer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarredAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mstart)\u001b[38;5;241m&\u001b[39m(stargazer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarredAt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m<\u001b[39mend)]\n\u001b[1;32m      8\u001b[0m project_star_df\u001b[38;5;241m.\u001b[39mappend(stargazer_df)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    566\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[0;31mValueError\u001b[0m: time data '2015-11-09T13:17:30Z' does not match format '%Y-%m-%d %H:%M:%S'"
     ]
    }
   ],
   "source": [
    "# read project star history\n",
    "project_star_df = []\n",
    "for path in repo_dirs:\n",
    "    stargazer_df = pd.read_csv(os.path.join(path, 'star_history.csv'), index_col=0)\n",
    "    #stargazer_df['starredAt'] = stargazer_df['starredAt'].apply(lambda x:datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    stargazer_df['starredAt'] = stargazer_df['starredAt'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "    stargazer_df = stargazer_df.loc[(stargazer_df['starredAt']>=start)&(stargazer_df['starredAt']<end)]\n",
    "    project_star_df.append(stargazer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read project commit data\n",
    "project_commit_df = []\n",
    "for proj_dir in repo_dirs:\n",
    "    commit_df = pd.read_csv(os.path.join(proj_dir,'commit_main.csv'), index_col=0)\n",
    "    commit_df['Time'] = pd.to_datetime(commit_df['Time'])\n",
    "    commit_df['Changed Files'] = commit_df['Changed Files'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    commit_df['Parents'] = commit_df['Parents'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    project_commit_df.append(commit_df)\n",
    "for df in project_commit_df:\n",
    "    df.set_index('Commit#', inplace=True)\n",
    "project_commit_dict = [df.to_dict(orient='index') for df in project_commit_df ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read project prs and issues\n",
    "project_pr_df = []\n",
    "for proj_dir in repo_dirs:    \n",
    "    pr_df = pd.read_csv(os.path.join(proj_dir,'pull_request_main.csv'), index_col=0)\n",
    "    pr_df['Opened time'] = pd.to_datetime(pr_df['Opened time'])\n",
    "    pr_df['Closed time'] = pd.to_datetime(pr_df['Closed time'])\n",
    "    pr_df['Labels'] = pr_df['Labels'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Assignees'] = pr_df['Assignees'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Reviewers'] = pr_df['Reviewers'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Participants'] = pr_df['Participants'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Commits'] = pr_df['Commits'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    project_pr_df.append(pr_df)\n",
    "project_pr_dict = [df.to_dict(orient='index') for df in project_pr_df ]\n",
    "\n",
    "project_issue_df = []\n",
    "for proj_dir in repo_dirs:  \n",
    "    issue_df = pd.read_csv(os.path.join(proj_dir,'issue_main.csv'), index_col=0)\n",
    "    issue_df['Opened time'] = pd.to_datetime(issue_df['Opened time'])\n",
    "    issue_df['Closed time'] = pd.to_datetime(issue_df['Closed time'])\n",
    "    issue_df['Labels'] = issue_df['Labels'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    issue_df['Assignees'] = issue_df['Assignees'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    issue_df['Participants'] = issue_df['Participants'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    project_issue_df.append(issue_df)\n",
    "project_issue_dict = [df.to_dict(orient='index') for df in project_issue_df ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 90-days periods for each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_stars(i,x):\n",
    "    return len(project_star_df[i].loc[(project_star_df[i]['starredAt']>= x['start'])&(project_star_df[i]['starredAt']< x['end'])])\n",
    "    \n",
    "def get_period_forks(i,x):\n",
    "    return len(project_fork_df[i].loc[(project_fork_df[i]['time']>= x['start'])&(project_fork_df[i]['time']< x['end'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_duration = []\n",
    "for i in range(len(projects)):\n",
    "    project_duration.append({'start':min(project_commit_df[i]['Time'].min(),project_issue_df[i]['Opened time'].min(),\n",
    "                                         project_pr_df[i]['Opened time'].min()),\n",
    "                            'end':end})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split project lifespan into 90 days periods\n",
    "num_days = 90\n",
    "project_stage_df = []\n",
    "project_metric = ['start', 'end','star','fork']\n",
    "for i in range(len(projects)):\n",
    "    df = pd.DataFrame(columns=project_metric)\n",
    "    bin_dates = [[],[]]\n",
    "    cur = project_duration[i]['start']\n",
    "    delta = datetime.timedelta(days=num_days)\n",
    "    while cur+delta < project_duration[i]['end']:\n",
    "        bin_dates[0].append(cur)\n",
    "        bin_dates[1].append(cur+delta)\n",
    "        cur += delta\n",
    "    df['start'] = bin_dates[0]\n",
    "    df['end'] = bin_dates[1]\n",
    "    project_stage_df.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin the number of forks and stars into 90 days periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(projects)):\n",
    "    project_stage_df[i]['project'] = projects[i]\n",
    "    project_stage_df[i]['period'] = project_stage_df[i].index\n",
    "    project_stage_df[i]['star'] = project_stage_df[i].apply(lambda x: get_period_stars(i,x), axis=1)\n",
    "    project_stage_df[i]['fork'] = project_stage_df[i].apply(lambda x: get_period_forks(i,x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the initial periods for pytorch and theano where the projects might not be public yet (fork=0)\n",
    "df = project_stage_df[projects.index('pytorch')]\n",
    "df = df.loc[~df['period'].between(0, 19)]\n",
    "df['period'] = df['period'].apply(lambda x:x-20)\n",
    "project_stage_df[projects.index('pytorch')] = df\n",
    "\n",
    "df = project_stage_df[projects.index('theano_aesara')]\n",
    "df = df.loc[~df['period'].between(0, 13)]\n",
    "df['period'] = df['period'].apply(lambda x:x-14)\n",
    "project_stage_df[projects.index('theano_aesara')] = df\n",
    "\n",
    "df = project_stage_df[projects.index('scikit-learn')]\n",
    "df = df.loc[~df['period'].between(0, 1)]\n",
    "df['period'] = df['period'].apply(lambda x:x-2)\n",
    "project_stage_df[projects.index('scikit-learn')] = df\n",
    "\n",
    "df = project_stage_df[projects.index('mxnet')]\n",
    "df = df.loc[~df['period']==0]\n",
    "df['period'] = df['period'].apply(lambda x:x-1)\n",
    "project_stage_df[projects.index('mxnet')] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all projects and obtain the dependent variables\n",
    "lemr_data = pd.concat(project_stage_df,ignore_index = True)\n",
    "lemr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare indenpendent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemr_data['project_code'] = lemr_data['project'].apply(lambda x:projects.index(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### workload composition related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(projects)):\n",
    "    periods = lemr_data.loc[lemr_data['project'] == projects[i]]['period'].unique()\n",
    "    for p in periods:\n",
    "        #print(projects[i],p)\n",
    "        try:\n",
    "            pavtivity = filtered_developer_period_df.loc[(filtered_developer_period_df['project'] == projects[i])&(filtered_developer_period_df['period'] == p)]\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern1_ratio'] = len(pavtivity.loc[pavtivity['wcp_code']==1])/len(pavtivity) if len(pavtivity) > 0 else 0\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern2_ratio'] = len(pavtivity.loc[pavtivity['wcp_code']==2])/len(pavtivity) if len(pavtivity) > 0 else 0\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern3_ratio'] = len(pavtivity.loc[pavtivity['wcp_code']==3])/len(pavtivity) if len(pavtivity) > 0 else 0\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern4_ratio'] = len(pavtivity.loc[pavtivity['wcp_code']==4])/len(pavtivity) if len(pavtivity) > 0 else 0\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern5_ratio'] = len(pavtivity.loc[pavtivity['wcp_code']==5])/len(pavtivity) if len(pavtivity) > 0 else 0\n",
    "            \n",
    "\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern1_commit_ratio'] = pavtivity.loc[pavtivity['wcp_code']==1]['commit'].sum()/pavtivity['commit'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern1_issue_ratio'] = pavtivity.loc[pavtivity['wcp_code']==1]['issue'].sum()/pavtivity['issue'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern1_issue_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==1]['issue comment'].sum()/pavtivity['issue comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern1_pr_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==1]['pr comment'].sum()/pavtivity['pr comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern1_review_ratio'] = pavtivity.loc[pavtivity['wcp_code']==1]['review'].sum()/pavtivity['review'].sum()\n",
    "\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern2_commit_ratio'] = pavtivity.loc[pavtivity['wcp_code']==2]['commit'].sum()/pavtivity['commit'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern2_issue_ratio'] = pavtivity.loc[pavtivity['wcp_code']==2]['issue'].sum()/pavtivity['issue'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern2_issue_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==2]['issue comment'].sum()/pavtivity['issue comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern2_pr_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==2]['pr comment'].sum()/pavtivity['pr comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern2_review_ratio'] = pavtivity.loc[pavtivity['wcp_code']==2]['review'].sum()/pavtivity['review'].sum()\n",
    "\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern3_commit_ratio'] = pavtivity.loc[pavtivity['wcp_code']==3]['commit'].sum()/pavtivity['commit'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern3_issue_ratio'] = pavtivity.loc[pavtivity['wcp_code']==3]['issue'].sum()/pavtivity['issue'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern3_issue_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==3]['issue comment'].sum()/pavtivity['issue comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern3_pr_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==3]['pr comment'].sum()/pavtivity['pr comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern3_review_ratio'] = pavtivity.loc[pavtivity['wcp_code']==3]['review'].sum()/pavtivity['review'].sum()\n",
    "\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern4_commit_ratio'] = pavtivity.loc[pavtivity['wcp_code']==4]['commit'].sum()/pavtivity['commit'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern4_issue_ratio'] = pavtivity.loc[pavtivity['wcp_code']==4]['issue'].sum()/pavtivity['issue'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern4_issue_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==4]['issue comment'].sum()/pavtivity['issue comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern4_pr_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==4]['pr comment'].sum()/pavtivity['pr comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern4_review_ratio'] = pavtivity.loc[pavtivity['wcp_code']==4]['review'].sum()/pavtivity['review'].sum()\n",
    "\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern5_commit_ratio'] = pavtivity.loc[pavtivity['wcp_code']==5]['commit'].sum()/pavtivity['commit'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern5_issue_ratio'] = pavtivity.loc[pavtivity['wcp_code']==5]['issue'].sum()/pavtivity['issue'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern5_issue_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==5]['issue comment'].sum()/pavtivity['issue comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern5_pr_comment_ratio'] = pavtivity.loc[pavtivity['wcp_code']==5]['pr comment'].sum()/pavtivity['pr comment'].sum()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pattern5_review_ratio'] = pavtivity.loc[pavtivity['wcp_code']==5]['review'].sum()/pavtivity['review'].sum()\n",
    "        except Exception as e:\n",
    "            print(projects[i],p)\n",
    "            print(e)\n",
    "            raise\n",
    "lemr_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify correlated variables\n",
    "workload_variables = [\n",
    "\n",
    "       'pattern1_ratio', 'pattern2_ratio', 'pattern3_ratio', 'pattern4_ratio', 'pattern5_ratio', \n",
    "       \n",
    "       'pattern1_commit_ratio', 'pattern1_issue_ratio',\n",
    "       'pattern1_issue_comment_ratio', 'pattern1_pr_comment_ratio',\n",
    "       'pattern1_review_ratio', 'pattern2_commit_ratio',\n",
    "       'pattern2_issue_ratio', 'pattern2_issue_comment_ratio',\n",
    "       'pattern2_pr_comment_ratio', 'pattern2_review_ratio',\n",
    "       'pattern3_commit_ratio', 'pattern3_issue_ratio',\n",
    "       'pattern3_issue_comment_ratio', 'pattern3_pr_comment_ratio',\n",
    "       'pattern3_review_ratio', 'pattern4_commit_ratio',\n",
    "       'pattern4_issue_ratio', 'pattern4_issue_comment_ratio',\n",
    "       'pattern4_pr_comment_ratio', 'pattern4_review_ratio',\n",
    "       'pattern5_commit_ratio', 'pattern5_issue_ratio',\n",
    "       'pattern5_issue_comment_ratio', 'pattern5_pr_comment_ratio',\n",
    "       'pattern5_review_ratio'\n",
    "]\n",
    "correlated_features = ['pattern1_commit_ratio','pattern1_issue_comment_ratio','pattern1_pr_comment_ratio','pattern1_review_ratio',\n",
    "                       'pattern2_pr_comment_ratio','pattern2_commit_ratio','pattern2_issue_ratio',\n",
    "                       'pattern3_commit_ratio','pattern3_issue_comment_ratio','pattern3_pr_comment_ratio',\n",
    "                       'pattern4_ratio','pattern4_issue_comment_ratio','pattern4_pr_comment_ratio',\n",
    "                       'pattern5_ratio','pattern5_commit_ratio','pattern5_issue_comment_ratio','pattern5_pr_comment_ratio']\n",
    "# in old paper\n",
    "# correlated_features = [ 'pattern1_commit_ratio', 'pattern1_issue_comment_ratio','pattern1_pr_comment_ratio',\n",
    "#                        'pattern2_pr_comment_ratio', 'pattern2_commit_ratio', \n",
    "#                        'pattern3_commit_ratio', 'pattern3_issue_comment_ratio', 'pattern3_pr_comment_ratio',\n",
    "#                        'pattern4_ratio', 'pattern4_issue_comment_ratio', 'pattern4_pr_comment_ratio',\n",
    "#                        'pattern5_ratio','pattern5_commit_ratio','pattern5_issue_ratio', 'pattern5_issue_comment_ratio', 'pattern5_pr_comment_ratio'\n",
    "                       \n",
    "#     ]\n",
    "workload_variables_noncor = [item for item in workload_variables if not item in correlated_features]\n",
    "correlation_matrix = lemr_data[workload_variables_noncor].corr(method='spearman')\n",
    "cutoff = (abs(correlation_matrix) > 0.5)\n",
    "correlated = [(col, row) for col in correlation_matrix.columns for row in correlation_matrix.index if cutoff.at[row, col] and not row==col]\n",
    "correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work preference related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(projects)):\n",
    "    periods = lemr_data.loc[lemr_data['project'] == projects[i]]['period'].unique()\n",
    "    for p in periods:\n",
    "        try:\n",
    "            pavtivity = filtered_developer_period_df.loc[(filtered_developer_period_df['project'] == projects[i])&(filtered_developer_period_df['period'] == p)]\n",
    "            if len(pavtivity) <= 0:\n",
    "                continue\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'binned_entropy'] = pavtivity['binned_entropy'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'c3(1)'] = pavtivity['c3(1)'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'c3(2)'] = pavtivity['c3(2)'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'c3(3)'] = pavtivity['c3(3)'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'number_cwt_peaks'] = pavtivity['number_cwt_peaks'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'longest_strike_above_mean'] = pavtivity['longest_strike_above_mean'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'longest_strike_below_mean'] = pavtivity['longest_strike_below_mean'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'balance'] = pavtivity['balance'].median()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'diverse'] = pavtivity['diverse'].median()\n",
    "         \n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'commit'] = pavtivity['commit'].mean()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'issue'] = pavtivity['issue'].mean()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'issue_comment'] = pavtivity['issue comment'].mean()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'pr_comment'] = pavtivity['pr comment'].mean()\n",
    "            lemr_data.loc[(lemr_data['project'] == projects[i])&(lemr_data['period'] == p), 'review'] = pavtivity['review'].mean()\n",
    "        except Exception as e:\n",
    "            print(projects[i],p)\n",
    "            print(e)\n",
    "            raise\n",
    "lemr_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify correlated variables\n",
    "work_preference_variables = ['period', 'binned_entropy', 'c3(1)', 'c3(2)', 'c3(3)', 'number_cwt_peaks', 'longest_strike_above_mean', \n",
    "                             'longest_strike_below_mean', 'diverse', 'balance', 'commit', 'issue', 'issue_comment', 'pr_comment', \n",
    "                             'review']\n",
    "#correlated_variables = ['binned_entropy', 'longest_strike_below_mean', 'c3(2)', 'c3(3)']\n",
    "correlated_variables =['longest_strike_above_mean', 'longest_strike_below_mean','number_cwt_peaks', 'c3(2)', 'c3(3)']\n",
    "# In old paper\n",
    "# correlated_variables = ['number_cwt_peaks','diverse', 'longest_strike_above_mean', 'c3(1)', 'c3(2)', 'c3(3)', 'pr_comment']\n",
    "work_preference_variables_noncor = [item for item in work_preference_variables if not item in correlated_variables]\n",
    "correlation_matrix = lemr_data[work_preference_variables_noncor].corr(method='spearman')\n",
    "cutoff = (abs(correlation_matrix) > 0.7)\n",
    "correlated = [(col, row) for col in correlation_matrix.columns for row in correlation_matrix.index if cutoff.at[row, col] and not row==col]\n",
    "correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed effect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install this package if you have not install it, otherwise donot run this cell\n",
    "utils = importr('utils')\n",
    "base = importr('base')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages('lme4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrow(num):\n",
    "    return '↗' if num > 0 else '↘'\n",
    "def signf_code(chisq):\n",
    "    if chisq <= 0.001:\n",
    "        return '***'\n",
    "    elif chisq <= 0.01:\n",
    "        return '**'\n",
    "    elif chisq <= 0.05:\n",
    "        return '*'\n",
    "    elif chisq <= 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(column):\n",
    "    col_min = column.min()\n",
    "    col_max = column.max()\n",
    "    if col_min == col_max:\n",
    "        return 0 if col_min == 0 else column / col_min\n",
    "    else:\n",
    "        return (column - col_min) / (col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mixedlm(formula, df, groups, reformula=None):\n",
    "    model = smf.mixedlm(formula, df, groups=groups, re_formula = reformula)\n",
    "    rslt = model.fit(method=[\"lbfgs\"])\n",
    "    pred = rslt.predict()\n",
    "    var_resid = rslt.scale\n",
    "    var_random_effect = float(rslt.cov_re.iloc[0][0])\n",
    "    var_fixed_effect = pred.var()\n",
    "    total_var = var_fixed_effect + var_random_effect + var_resid\n",
    "    marginal_r2 = var_fixed_effect / total_var\n",
    "    conditional_r2 = (var_fixed_effect + var_random_effect) / total_var\n",
    "    return marginal_r2, conditional_r2, rslt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: work preference - star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"star ~ \" + ' + '.join(work_preference_variables_noncor)\n",
    "print(formula)\n",
    "# Remove the initial period\n",
    "df = lemr_data.loc[lemr_data['period']!=0]\n",
    "for i in range(len(projects)):\n",
    "    df.loc[df['project']==projects[i],'star'] = min_max_normalize(df.loc[df['project']==projects[i]]['star'])\n",
    "    df.loc[df['project']==projects[i],'fork'] = min_max_normalize(df.loc[df['project']==projects[i]]['fork'])\n",
    "df[['project', 'star','fork']]\n",
    "mr2, cr2, rslt = fit_mixedlm(formula, df, df['project_code'])\n",
    "print('conditional r2', cr2)\n",
    "print('marginal r2', mr2)\n",
    "print(rslt.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_summary = rslt.pvalues.apply(signf_code).to_frame(name='Signif.')\n",
    "rslt_summary['Rel.'] = rslt.params.apply(arrow)\n",
    "rslt_summary.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: work preference - fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"fork ~ \" + ' + '.join(work_preference_variables_noncor)\n",
    "print(formula)\n",
    "df = lemr_data.loc[lemr_data['period']!=0]\n",
    "for i in range(len(projects)):\n",
    "    df.loc[df['project']==projects[i],'star'] = min_max_normalize(df.loc[df['project']==projects[i]]['star'])\n",
    "    df.loc[df['project']==projects[i],'fork'] = min_max_normalize(df.loc[df['project']==projects[i]]['fork'])\n",
    "df[['project', 'star','fork']]\n",
    "mr2, cr2, rslt = fit_mixedlm(formula, df, df['project_code'])\n",
    "print('conditional r2', cr2)\n",
    "print('marginal r2', mr2)\n",
    "print(rslt.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_summary = rslt.pvalues.apply(signf_code).to_frame(name='Signif.')\n",
    "rslt_summary['Rel.'] = rslt.params.apply(arrow)\n",
    "rslt_summary.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: workload composition - star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"star ~ \" + ' + '.join(workload_variables_noncor)\n",
    "print(formula)\n",
    "df = lemr_data.loc[lemr_data['period']!=0]\n",
    "for i in range(len(projects)):\n",
    "    df.loc[df['project']==projects[i],'star'] = min_max_normalize(df.loc[df['project']==projects[i]]['star'])\n",
    "    df.loc[df['project']==projects[i],'fork'] = min_max_normalize(df.loc[df['project']==projects[i]]['fork'])\n",
    "df[['project', 'star','fork']]\n",
    "mr2, cr2, rslt = fit_mixedlm(formula, df, df['project_code'])\n",
    "print('conditional r2', cr2)\n",
    "print('marginal r2', mr2)\n",
    "print(rslt.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_summary = rslt.pvalues.apply(signf_code).to_frame(name='Signif.')\n",
    "rslt_summary['Rel.'] = rslt.params.apply(arrow)\n",
    "rslt_summary.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: workload composition - fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"fork ~ \" + ' + '.join(workload_variables_noncor)\n",
    "print(formula)\n",
    "df = lemr_data.loc[lemr_data['period']!=0]\n",
    "for i in range(len(projects)):\n",
    "    df.loc[df['project']==projects[i],'star'] = min_max_normalize(df.loc[df['project']==projects[i]]['star'])\n",
    "    df.loc[df['project']==projects[i],'fork'] = min_max_normalize(df.loc[df['project']==projects[i]]['fork'])\n",
    "df[['project', 'star','fork']]\n",
    "mr2, cr2, rslt = fit_mixedlm(formula, df, df['project_code'])\n",
    "print('conditional r2', cr2)\n",
    "print('marginal r2', mr2)\n",
    "print(rslt.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_summary = rslt.pvalues.apply(signf_code).to_frame(name='Signif.')\n",
    "rslt_summary['Rel.'] = rslt.params.apply(arrow)\n",
    "rslt_summary.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
