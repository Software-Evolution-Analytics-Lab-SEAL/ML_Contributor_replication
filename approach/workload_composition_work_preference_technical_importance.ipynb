{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102cd535-7b65-4e36-8843-5dd5ea12c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from itertools import chain\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import feature_calculators as fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d0c92",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9a6758-12f6-47b9-86a5-1b8c4b719326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_handler(date_str):\n",
    "    return datetime.datetime.fromisoformat(date_str.split()[0])\n",
    "def get_timezone(date_time_str):\n",
    "    print(date_time_str)\n",
    "    ts = time.mktime(datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "    utc_offset = datetime.datetime.fromtimestamp(ts) - datetime.datetime.utcfromtimestamp(ts)\n",
    "    return utc_offset\n",
    "def date_time_handler(date_time_str):\n",
    "    return datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b411745-ee17-49b3-a015-2d6a0f641925",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.join(os.getcwd(), '..','data')\n",
    "proj_names = ['tensorflow_tensorflow',\n",
    "              'pytorch_pytorch',\n",
    "                'scikit-learn_scikit-learn',\n",
    "                'keras-team_keras',\n",
    "                'apache_mxnet',\n",
    "                'theano_aesara',\n",
    "                'onnx_onnx',\n",
    "                'deeplearning4j_deeplearning4j']\n",
    "\n",
    "repo_dirs = [os.path.join(basedir,item) for item in proj_names]\n",
    "\n",
    "projects = ['tensorflow', 'pytorch', 'scikit-learn', 'keras', 'mxnet', 'theano_aesara', 'onnx', 'deeplearning4j']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dae225",
   "metadata": {},
   "source": [
    "### read contributor features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d958c2-5f2b-47b4-8e45-0b67f0b3c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_data = pd.read_csv(os.path.join(basedir, \"contributor_features.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9186109-065d-4c24-8e53-68e1c7503a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# studied period of the projects\n",
    "start = datetime.datetime(2008,1,1)\n",
    "end = datetime.datetime(2022,4,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12cf7c0",
   "metadata": {},
   "source": [
    "### read contributor features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e572d42-4875-4699-be02-f1a039c9f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_data = pd.read_csv(os.path.join(basedir, \"contributor_features.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fd3a5",
   "metadata": {},
   "source": [
    "### read commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86caef4a-16ab-4757-9a3b-aaa050a2a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commit_df = []\n",
    "for proj_dir in repo_dirs:\n",
    "    commit_df = pd.read_csv(os.path.join(proj_dir,'commit_main.csv'), index_col=0)\n",
    "    commit_df['Time'] = pd.to_datetime(commit_df['Time'])\n",
    "    commit_df['Changed Files'] = commit_df['Changed Files'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    commit_df['Parents'] = commit_df['Parents'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    project_commit_df.append(commit_df)\n",
    "for df in project_commit_df:\n",
    "    df.set_index('Commit#', inplace=True)\n",
    "project_commit_dict = [df.to_dict(orient='index') for df in project_commit_df ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb05263-227d-46e4-a710-96dfcb32e39f",
   "metadata": {},
   "source": [
    "### read pr and issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8586e754-ac6d-4882-be66-0b2d7a0a721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_pr_df = []\n",
    "for proj_dir in repo_dirs:    \n",
    "    pr_df = pd.read_csv(os.path.join(proj_dir,'pull_request_main.csv'), index_col=0)\n",
    "    pr_df['Opened time'] = pd.to_datetime(pr_df['Opened time'])\n",
    "    pr_df['Closed time'] = pd.to_datetime(pr_df['Closed time'])\n",
    "    pr_df['Labels'] = pr_df['Labels'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Assignees'] = pr_df['Assignees'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Reviewers'] = pr_df['Reviewers'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Participants'] = pr_df['Participants'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    pr_df['Commits'] = pr_df['Commits'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    project_pr_df.append(pr_df)\n",
    "project_pr_dict = [df.to_dict(orient='index') for df in project_pr_df ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_issue_df = []\n",
    "for proj_dir in repo_dirs:  \n",
    "    issue_df = pd.read_csv(os.path.join(proj_dir,'issue_main.csv'), index_col=0)\n",
    "    issue_df['Opened time'] = pd.to_datetime(issue_df['Opened time'])\n",
    "    issue_df['Closed time'] = pd.to_datetime(issue_df['Closed time'])\n",
    "    issue_df['Labels'] = issue_df['Labels'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    issue_df['Assignees'] = issue_df['Assignees'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    issue_df['Participants'] = issue_df['Participants'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    project_issue_df.append(issue_df)\n",
    "project_issue_dict = [df.to_dict(orient='index') for df in project_issue_df ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8484f",
   "metadata": {},
   "source": [
    "### read pr and issue comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab468d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_comments_dict = []\n",
    "for proj_dir in repo_dirs:  \n",
    "    with open(os.path.join(proj_dir, 'pr_comment_time.json'), 'r') as json_file:\n",
    "        pr_comment_dict = json.load(json_file)\n",
    "        pr_comment_dict = {key: list(map(lambda x: date_time_handler(x), value)) for key, value in pr_comment_dict.items()}\n",
    "        pr_comments_dict.append(pr_comment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c204a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_comments_dict = []\n",
    "for proj_dir in repo_dirs:  \n",
    "    with open(os.path.join(proj_dir, 'issue_comment_time.json'), 'r') as json_file:\n",
    "        issue_comment_dict = json.load(json_file)\n",
    "        issue_comment_dict = {key: list(map(lambda x: date_time_handler(x), value)) for key, value in issue_comment_dict.items()}\n",
    "        issue_comments_dict.append(issue_comment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee38a4b",
   "metadata": {},
   "source": [
    "## Generate contributor period OSS activities (build workload composition vector space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff722e59-ed63-4a9d-9a69-68f978c83087",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict = []\n",
    "for i in range(len(projects)):\n",
    "    proj_dict = {}\n",
    "    for idx in project_pr_dict[i]:\n",
    "        if len(project_pr_dict[i][idx]['Reviewers']) > 0:\n",
    "            for reviewer in project_pr_dict[i][idx]['Reviewers']:\n",
    "                if reviewer in proj_dict:\n",
    "                    proj_dict[reviewer].append(project_pr_dict[i][idx]['Opened time'])\n",
    "                else:\n",
    "                    proj_dict[reviewer] = [project_pr_dict[i][idx]['Opened time']]\n",
    "    review_dict.append(proj_dict)\n",
    "    \n",
    "commit_dict = []\n",
    "for i in range(len(projects)):\n",
    "    proj_dict = project_commit_df[i].groupby(['Author'])['Time'].apply(list).to_dict()\n",
    "    commit_dict.append(proj_dict)\n",
    "\n",
    "issue_dict = []\n",
    "for i in range(len(projects)):\n",
    "    proj_dict = project_issue_df[i].groupby(['Owner'])['Opened time'].apply(list).to_dict()\n",
    "    issue_dict.append(proj_dict)\n",
    "\n",
    "activity_dict = []\n",
    "for i in range(len(projects)):\n",
    "    proj_dict = {}\n",
    "    for dev in developer_data.loc[developer_data['project']==projects[i]]['name'].to_list():\n",
    "        proj_dict[dev] = []\n",
    "        if dev in issue_dict[i]:\n",
    "            l = list(map(lambda x:('issue',x), issue_dict[i][dev]))\n",
    "            proj_dict[dev].extend(l)\n",
    "        if dev in review_dict[i]:\n",
    "            l = list(map(lambda x:('review',x), review_dict[i][dev]))\n",
    "            proj_dict[dev].extend(l)\n",
    "        if dev in issue_comments_dict[i]:\n",
    "            l = list(map(lambda x:('issue comment',x), issue_comments_dict[i][dev]))\n",
    "            proj_dict[dev].extend(l)\n",
    "        if dev in pr_comments_dict[i]:\n",
    "            l = list(map(lambda x:('pr comment',x), pr_comments_dict[i][dev]))\n",
    "            proj_dict[dev].extend(l)\n",
    "        if dev in commit_dict[i]:\n",
    "            l = list(map(lambda x:('commit',x), commit_dict[i][dev]))\n",
    "            proj_dict[dev].extend(l)\n",
    "        proj_dict[dev] = sorted(proj_dict[dev], key = lambda x:x[1])\n",
    "    activity_dict.append(proj_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd949c9f",
   "metadata": {},
   "source": [
    "### Get 90-days periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0837e345-c74e-4839-b617-d06608f49ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_duration = []\n",
    "end = datetime.datetime(2024,1,1)\n",
    "for i in range(len(projects)):\n",
    "    project_duration.append({'start':min(project_commit_df[i]['Time'].min(),project_issue_df[i]['Opened time'].min(),project_pr_df[i]['Opened time'].min()),\n",
    "                            'end':end})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5574764-71a6-44b1-b184-ad183c76b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = 90\n",
    "project_stage_df = []\n",
    "for i in range(len(projects)):\n",
    "    df = pd.DataFrame()\n",
    "    bin_dates = [[],[]]\n",
    "    cur = project_duration[i]['start']\n",
    "    delta = datetime.timedelta(days=num_days)\n",
    "    while cur+delta < project_duration[i]['end']:\n",
    "        bin_dates[0].append(cur)\n",
    "        bin_dates[1].append(cur+delta)\n",
    "        cur += delta\n",
    "    df['start'] = bin_dates[0]\n",
    "    df['end'] = bin_dates[1]\n",
    "    project_stage_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59390452",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(projects)):\n",
    "    star_df = pd.read_csv(os.path.join(repo_dirs[i],'star_history.csv'))\n",
    "    star_df['starredAt'] = pd.to_datetime(star_df['starredAt'])\n",
    "    fork_df = pd.read_csv(os.path.join(repo_dirs[i],'fork_history.csv'))\n",
    "    fork_df['time'] = pd.to_datetime(fork_df['time'])\n",
    "\n",
    "    # Add a column to df1 that counts how many dates in df2 fall within the start and end period\n",
    "    project_stage_df[i]['star'] = project_stage_df[i].apply(lambda row: ((star_df['starredAt'] >= row['start']) & (star_df['starredAt'] < row['end'])).sum(), axis=1)\n",
    "    project_stage_df[i]['fork'] = project_stage_df[i].apply(lambda row: ((fork_df['time'] >= row['start']) & (fork_df['time'] < row['end'])).sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15825b22",
   "metadata": {},
   "source": [
    "### Get developer OSS activities per period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7acea3d6-dd69-4085-8dc5-f02b1d919a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_developer_period_commit(i,x):\n",
    "    developer_commits = project_commit_df[i].loc[(project_commit_df[i]['Time']>= x['start'])&(project_commit_df[i]['Time']< x['end'])].groupby(['Author']).size().to_dict()\n",
    "    developers = developer_data.loc[developer_data['project']==projects[i]]['name'].to_list()\n",
    "    filtered = {}\n",
    "    for d in developers:\n",
    "        if d in developer_commits:\n",
    "            filtered[d] = developer_commits[d]\n",
    "        else:\n",
    "            filtered[d] = 0\n",
    "    return filtered\n",
    "def get_developer_period_issue(i,x):\n",
    "    developer_issues = project_issue_df[i].loc[(project_issue_df[i]['Opened time']>= x['start'])&(project_issue_df[i]['Opened time']< x['end'])].groupby(['Owner'])['Opened time'].count().to_dict()\n",
    "    developers = developer_data.loc[developer_data['project']==projects[i]]['name'].to_list()\n",
    "    filtered = {}\n",
    "    for d in developers:\n",
    "        if d in developer_issues:\n",
    "            filtered[d] = developer_issues[d]\n",
    "        else:\n",
    "            filtered[d] = 0\n",
    "    return filtered\n",
    "\n",
    "def get_developer_period_issue_comment(i,x):\n",
    "    issue_comments = {}\n",
    "    developers = developer_data.loc[developer_data['project']==projects[i]]['name'].to_list()\n",
    "    for d in developers:\n",
    "        if d in issue_comments_dict[i]:\n",
    "            issue_comments[d] = len(list(filter(lambda day: day>= x['start'] and day<x['end'], issue_comments_dict[i][d])))\n",
    "        else:\n",
    "            issue_comments[d] = 0\n",
    "    return issue_comments\n",
    "\n",
    "def get_developer_period_pr_comment(i,x):\n",
    "    pr_comments = {}\n",
    "    developers = developer_data.loc[developer_data['project']==projects[i]]['name'].to_list()\n",
    "    for d in developers:\n",
    "        if d in pr_comments_dict[i]:\n",
    "            pr_comments[d] = len(list(filter(lambda day: day>= x['start'] and day<x['end'], pr_comments_dict[i][d])))\n",
    "        else:\n",
    "            pr_comments[d] = 0\n",
    "    return pr_comments\n",
    "def get_developer_period_review(i,x):\n",
    "    review = {}\n",
    "    developers = developer_data.loc[developer_data['project']==projects[i]]['name'].to_list()\n",
    "    for d in developers:\n",
    "        if d in review_dict[i]:\n",
    "            review[d] = len(list(filter(lambda day: day>= x['start'] and day<x['end'], review_dict[i][d])))\n",
    "        else:\n",
    "            review[d] = 0\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1ec3255-6bca-4c44-a69d-dd4687664b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_data['join date'] = developer_data['join date'].apply(date_time_handler)\n",
    "developer_data['last active'] = developer_data['last active'].apply(date_time_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9dd7d4-f158-41ee-b79c-c378c707226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['commit','issue', 'issue comment','pr comment',  'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caf1403b-80ee-45b5-b326-f923e04fbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take around 5 min\n",
    "developer_period_df = []\n",
    "for i in range(len(projects)):\n",
    "    developers = developer_data.loc[developer_data['project']==projects[i]]['name'].to_list()\n",
    "    profiles = developer_data.loc[developer_data['project']==projects[i]]['profile'].to_list()\n",
    "    proj_period_df = []\n",
    "    for d in developers:\n",
    "        for index, row in project_stage_df[i].iterrows():\n",
    "            proj_period_df.append([d,projects[i],profiles[developers.index(d)],index,row['start'], row['end']])\n",
    "    proj_period_df = pd.DataFrame(proj_period_df, columns=['name', 'project','profile','period', 'start','end'])\n",
    "    temp_commit = project_stage_df[i].apply(lambda x:get_developer_period_commit(i,x), axis=1)\n",
    "    temp_issue = project_stage_df[i].apply(lambda x:get_developer_period_issue(i,x), axis=1)\n",
    "    temp_issue_comment = project_stage_df[i].apply(lambda x:get_developer_period_issue_comment(i,x), axis=1)\n",
    "    temp_pr_comment = project_stage_df[i].apply(lambda x:get_developer_period_pr_comment(i,x), axis=1)\n",
    "    temp_review = project_stage_df[i].apply(lambda x:get_developer_period_review(i,x), axis=1)\n",
    "    for p in project_stage_df[i].index:\n",
    "        proj_period_df.loc[proj_period_df['period'] == p, 'commit'] = list(temp_commit[p].values())\n",
    "        proj_period_df.loc[proj_period_df['period'] == p, 'issue'] = list(temp_issue[p].values())\n",
    "        proj_period_df.loc[proj_period_df['period'] == p, 'issue comment'] = list(temp_issue_comment[p].values())\n",
    "        proj_period_df.loc[proj_period_df['period'] == p, 'pr comment'] = list(temp_pr_comment[p].values())\n",
    "        proj_period_df.loc[proj_period_df['period'] == p, 'review'] = list(temp_review[p].values())\n",
    "    developer_period_df.append(proj_period_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29f25bfd-682e-453a-a8a6-b43be572a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged the contributor activity dataframe for all projects\n",
    "# Remove the initial periods for pytorch and theano where the projects might not be public yet (fork=0)\n",
    "merged_developer_period_df = pd.concat(developer_period_df, ignore_index=True)\n",
    "filtered_developer_period_df = merged_developer_period_df.loc[merged_developer_period_df[features].sum(axis=1) > 0]\n",
    "filtered_developer_period_df = filtered_developer_period_df.loc[~((filtered_developer_period_df['project'] =='pytorch') & (filtered_developer_period_df['period'].between(0, 19)))]\n",
    "filtered_developer_period_df = filtered_developer_period_df.loc[~((filtered_developer_period_df['project'] =='scikit-learn') & (filtered_developer_period_df['period'].between(0, 1)))]\n",
    "filtered_developer_period_df = filtered_developer_period_df.loc[~((filtered_developer_period_df['project'] =='mxnet') & (filtered_developer_period_df['period']==0))]\n",
    "filtered_developer_period_df = filtered_developer_period_df.loc[~((filtered_developer_period_df['project'] =='theano_aesara') & (filtered_developer_period_df['period'].between(0, 13)))]\n",
    "filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='pytorch', 'period'] = filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='pytorch', 'period'].apply(lambda x:x-20)\n",
    "filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='scikit-learn', 'period'] = filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='scikit-learn', 'period'].apply(lambda x:x-2)\n",
    "filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='mxnet', 'period'] = filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='mxnet', 'period'].apply(lambda x:x-1)\n",
    "filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='theano_aesara', 'period'] = filtered_developer_period_df.loc[filtered_developer_period_df['project'] =='theano_aesara', 'period'].apply(lambda x:x-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ec5f4",
   "metadata": {},
   "source": [
    "### Normalize the OSS activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce04aa9a-9a71-475e-a9bd-eafe912cbe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_feature = ['commit_norm', 'issue_norm', 'issue_comment_norm', 'pr_comment_norm', 'review_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39f803-01a8-4507-bbc3-da250f5597f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(column):\n",
    "    col_min = column.min()\n",
    "    col_max = column.max()\n",
    "    if col_min == col_max:\n",
    "        return 0 if col_min == 0 else column / col_min\n",
    "    else:\n",
    "        return (column - col_min) / (col_max - col_min)\n",
    "\n",
    "for i in range(len(projects)):\n",
    "    proj = projects[i]\n",
    "    periods = filtered_developer_period_df.loc[filtered_developer_period_df['project']==proj]['period'].value_counts().index\n",
    "    for p in periods:\n",
    "        idxs = filtered_developer_period_df.loc[(filtered_developer_period_df['project']==proj)&(filtered_developer_period_df['period']==p)].index\n",
    "        filtered_developer_period_df.loc[idxs,'commit_norm'] = min_max_normalize(filtered_developer_period_df.loc[idxs]['commit'] )\n",
    "        filtered_developer_period_df.loc[idxs,'issue_norm'] = min_max_normalize(filtered_developer_period_df.loc[idxs]['issue'] )\n",
    "        filtered_developer_period_df.loc[idxs,'issue_comment_norm'] = min_max_normalize(filtered_developer_period_df.loc[idxs]['issue comment'] )\n",
    "        filtered_developer_period_df.loc[idxs,'pr_comment_norm'] = min_max_normalize(filtered_developer_period_df.loc[idxs]['pr comment'] )\n",
    "        filtered_developer_period_df.loc[idxs,'review_norm'] = min_max_normalize(filtered_developer_period_df.loc[idxs]['review'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe003fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_variance = filtered_developer_period_df[normalized_feature].std() == 0\n",
    "print(f\"Columns with zero variance: {zero_variance[zero_variance].index.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f5610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of zero vectors: ',len(filtered_developer_period_df.loc[filtered_developer_period_df[normalized_feature].sum(axis=1) <= 0]))\n",
    "filtered_developer_period_df = filtered_developer_period_df.loc[filtered_developer_period_df[normalized_feature].sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06208d70-4d9e-46f6-bf41-f676cafbc990",
   "metadata": {},
   "source": [
    "## Identify workload composition pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## read from existing filtered_developer_period_df\n",
    "# filtered_developer_period_df = pd.read_csv(os.path.join(basedir,'contributor_period_activity.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daac9c8",
   "metadata": {},
   "source": [
    "### Compute cosine similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe0a72-8f98-4bd6-806f-1a63095e9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = normalized_feature\n",
    "cosine_sim_matrix = cosine_similarity(filtered_developer_period_df[f])\n",
    "cosine_dist_matrix = 1-cosine_sim_matrix\n",
    "cosine_dist_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7074b",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering - Gradient Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c207123-4d0a-4fbf-bdd1-2adbd4062f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.75, 0.8,0.85,0.9,0.95,0.96,0.97,0.98,0.99]\n",
    "threshold = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.75, 0.8,0.85,0.9,0.95,0.96,0.97,0.98,0.99]\n",
    "sil = []\n",
    "num_clusters = []\n",
    "distance =linkage(filtered_developer_period_df[f],\"complete\", metric=\"cosine\")\n",
    "for th in threshold:\n",
    "    labels =fcluster(distance, th, criterion=\"distance\")\n",
    "    sil.append(silhouette_score(cosine_dist_matrix, labels))\n",
    "    num_clusters.append(len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda60c8-31a4-4f98-9615-5ba194aa23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=num_clusters,y=sil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9755a",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c404774-1187-40de-980c-b750e1dc3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance =linkage(filtered_developer_period_df[f],\"complete\", metric=\"cosine\")\n",
    "clst5 = fcluster(distance, 0.9999, criterion=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(cosine_dist_matrix, clst5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff9083",
   "metadata": {},
   "source": [
    "### Summarize workload composition patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d963f5-4b48-4bd0-8bf9-0062664fc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(clst5, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_names = ['PR Discussant', 'Issue Reporter', 'Code Reviewer', 'Committer', 'Issue Discussant']\n",
    "pattern_code = [4,1,5,3,2]\n",
    "filtered_developer_period_df['wcp'] = clst5\n",
    "filtered_developer_period_df['wcp'] = filtered_developer_period_df['wcp'].apply(lambda x:pattern_names[x-1])\n",
    "filtered_developer_period_df['wcp_code'] = filtered_developer_period_df['wcp'].apply(lambda x:pattern_code[pattern_names.index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6dfa91f-245d-4660-84d0-c5c58d809cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the center point of each pattern\n",
    "centers = []\n",
    "for i in np.unique(clst5):\n",
    "    indices = np.where(clst5 == i)[0]\n",
    "    cluster_dist = cosine_sim_matrix[indices]\n",
    "    cluster_dist = cluster_dist[:, indices]\n",
    "    sum_distances = np.sum(cluster_dist, axis=1)\n",
    "    centroid_index = np.argmax(sum_distances)\n",
    "    centroid = filtered_developer_period_df.iloc[indices[centroid_index]]\n",
    "    centers.append(centroid)\n",
    "centers = pd.DataFrame(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32fc716-9225-4315-98b8-ebfc2c33239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    #print('pattern:',i)\n",
    "    print('pattern:', centers.iloc[i]['wcp'],  centers.iloc[i]['wcp_code'])\n",
    "    angles = [n / float(5) * 2 * math.pi for n in range(5)]\n",
    "    angles += angles[:1]\n",
    "    values =  list( centers.iloc[i][normalized_feature].values)\n",
    "    values += values[:1]\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "     \n",
    "    # Draw one axe per variable + add labels\n",
    "    plt.xticks(angles[:-1], features, color='black', size=22)\n",
    "     \n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], ['0','0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9','1'], color=\"grey\", size=7)\n",
    "    #plt.ylim([0, 1])\n",
    "     \n",
    "    # Plot data\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    "     \n",
    "    # Fill area\n",
    "    ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n",
    "    plt.savefig(os.path.join(basedir,f\"workload_pattern_{pattern_code[i]}.png\"),dpi=300,bbox_inches='tight',facecolor='none')\n",
    "    # Show the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b24537",
   "metadata": {},
   "source": [
    "## Extract work preference features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca429dd",
   "metadata": {},
   "source": [
    "### Get OSS activity time series per period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take 5 mins\n",
    "def get_period_activity_time_series(row, activity_name=None):\n",
    "    days = int((row['end'] - row['start']).days)\n",
    "    bin = [0 for i in range(days)]\n",
    "    activities = activity_dict[projects.index(row['project'])][row['name']]\n",
    "    activities = list(filter(lambda x: x[1]>=row['start'] and x[1] <row['end'], activities))\n",
    "    if activity_name:\n",
    "        activities = list(filter(lambda x: x[0]==activity_name, activities))\n",
    "    activities = list(map(lambda x:int((x[1]-row['start']).days), activities))\n",
    "    for d in activities:\n",
    "        bin[d] += 1\n",
    "    return bin\n",
    "filtered_developer_period_df[['commit ts',\t'issue ts',\t'issue comment ts', 'pr comment ts', 'review ts']] = None\n",
    "filtered_developer_period_df['commit ts'] = filtered_developer_period_df.apply(lambda x:get_period_activity_time_series(x,'commit'), axis=1)\n",
    "filtered_developer_period_df['issue ts'] = filtered_developer_period_df.apply(lambda x:get_period_activity_time_series(x,'issue'), axis=1)\n",
    "filtered_developer_period_df['issue comment ts'] = filtered_developer_period_df.apply(lambda x:get_period_activity_time_series(x,'issue comment'), axis=1)\n",
    "filtered_developer_period_df['pr comment ts'] = filtered_developer_period_df.apply(lambda x:get_period_activity_time_series(x,'pr comment'), axis=1)\n",
    "filtered_developer_period_df['review ts'] = filtered_developer_period_df.apply(lambda x:get_period_activity_time_series(x,'review'), axis=1)\n",
    "filtered_developer_period_df['all activity ts'] = filtered_developer_period_df.apply(lambda x:get_period_activity_time_series(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698d908",
   "metadata": {},
   "source": [
    "### tsfresh time series feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f14863",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_features = filtered_developer_period_df[['name', 'project', 'profile', 'period', 'all activity ts', 'wcp_code']]\n",
    "tsfresh_features = ['number_cwt_peaks','binned_entropy','longest_strike_above_mean', 'longest_strike_below_mean', 'c3(1)', 'c3(2)', 'c3(3)']\n",
    "ts_features['number_cwt_peaks']  = ts_features['all activity ts'].apply(lambda x:fc.number_cwt_peaks(np.array(x), 5 ))\n",
    "ts_features['approximate_entropy']  = ts_features['all activity ts'].apply(lambda x:fc.approximate_entropy(np.array(x), 2,0.1 ))\n",
    "ts_features['binned_entropy'] = ts_features['all activity ts'].apply(lambda x:fc.binned_entropy(np.array(x), 10)) # level of disorder, unpredictability, or randomness\n",
    "ts_features['cid_ce'] = ts_features['all activity ts'].apply(lambda x:fc.cid_ce(np.array(x), False)) #complexity \n",
    "ts_features['sample_entropy'] = ts_features['all activity ts'].apply(lambda x:fc.sample_entropy(np.array(x))) #complexity \n",
    "\n",
    "ts_features['value_count'] = ts_features['all activity ts'].apply(lambda x:fc.value_count(np.array(x),0))\n",
    "ts_features['count_below'] = ts_features['all activity ts'].apply(lambda x:fc.count_below(np.array(x),0))\n",
    "ts_features['longest_strike_above_mean']  = ts_features['all activity ts'].apply(lambda x:fc.longest_strike_above_mean(np.array(x))/len(x)) # ratio\n",
    "ts_features['longest_strike_below_mean']  = ts_features['all activity ts'].apply(lambda x:fc.longest_strike_below_mean(np.array(x))/len(x)) # ratio\n",
    "\n",
    "\n",
    "ts_features['c3(1)'] = ts_features['all activity ts'].apply(lambda x:fc.c3(np.array(x),1))\n",
    "ts_features['c3(2)'] = ts_features['all activity ts'].apply(lambda x:fc.c3(np.array(x),2))\n",
    "ts_features['c3(3)'] = ts_features['all activity ts'].apply(lambda x:fc.c3(np.array(x),3))\n",
    "ts_features['mean_change'] = ts_features['all activity ts'].apply(lambda x:fc.mean_change(np.array(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ecd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_developer_period_df[tsfresh_features] = ts_features[tsfresh_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321c9d6",
   "metadata": {},
   "source": [
    "### diverse and balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_preference_features = tsfresh_features + ['balance','diverse']\n",
    "filtered_developer_period_df['diverse'] = (filtered_developer_period_df[features] != 0).sum(axis=1)\n",
    "filtered_developer_period_df['balance'] = 1/filtered_developer_period_df[normalized_feature].std(axis=1)\n",
    "# replace inf with a big number to prevent future calculation problems\n",
    "filtered_developer_period_df['balance'].replace([np.inf], 6000, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43ed8b",
   "metadata": {},
   "source": [
    "## Technical Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9afc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(projects)):\n",
    "    proj_commit = project_commit_dict[i]\n",
    "    file_graph = nx.Graph()\n",
    "    file_graph.add_node('root')\n",
    "    commit_sorted = dict(sorted(proj_commit.items(), key=lambda item: item[1]['Time']))\n",
    "    for commit_id in commit_sorted:\n",
    "        commit = commit_sorted[commit_id]\n",
    "        files = commit['Changed Files']\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                file_parts = file.split('/')\n",
    "                file_graph.add_node(file_parts[0])\n",
    "                file_graph.add_edge('root', file_parts[0])\n",
    "                if len(file_parts) > 1:\n",
    "                    current_node = file_parts[0]\n",
    "                    for part in file_parts[1:]:\n",
    "                        file_graph.add_node(os.path.join(current_node, part))\n",
    "                        file_graph.add_edge(current_node, os.path.join(current_node, part))\n",
    "                        current_node = os.path.join(current_node, part)\n",
    "        #     graph_eigenvector_centrality = nx.eigenvector_centrality(file_graph)\n",
    "        #     file_eigenvector_centrality = list(map(lambda x:graph_eigenvector_centrality[x], files))\n",
    "        #     commit['centrality'] = file_eigenvector_centrality   \n",
    "        # else:\n",
    "        #     commit['centrality'] = []\n",
    "                        \n",
    "    eigenvector_centrality = nx.eigenvector_centrality(file_graph,max_iter=500)\n",
    "    project_commit_df[i]['centrality'] = project_commit_df[i]['Changed Files'].apply(lambda x:[eigenvector_centrality[item] for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed4e9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(projects)):\n",
    "    project_commit_df[i]['sum centrality'] = project_commit_df[i]['centrality'].apply(lambda x:np.sum(x) if len(x) > 0 else 0)\n",
    "    project_commit_df[i]['max centrality'] = project_commit_df[i]['centrality'].apply(lambda x:np.max(x) if len(x) > 0 else 0)\n",
    "    project_commit_df[i]['avg centrality'] = project_commit_df[i]['centrality'].apply(lambda x:np.mean(x)  if len(x) > 0 else 0)\n",
    "    project_commit_df[i]['med centrality'] = project_commit_df[i]['centrality'].apply(lambda x:np.median(x)  if len(x) > 0 else 0)\n",
    "project_commits = [item.to_dict('index') for item in project_commit_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e7834a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_centrality(row, commit_ids, commit_dict, commit_metric = 'avg', period_metric = 'sum'):\n",
    "    if len(commit_ids) <= 0:\n",
    "        return 0\n",
    "    commit_metric = commit_metric +' centrality'\n",
    "    commit_ids = sorted(commit_ids, key=lambda x:commit_dict[x]['Time'])\n",
    "    commit_ids = list(filter(lambda x: commit_dict[x]['Time'] >= row['start'] and commit_dict[x]['Time'] < row['end'], commit_ids))\n",
    "    if len(commit_ids) <= 0:\n",
    "        return 0\n",
    "    period_commit_centrality = [commit_dict[idx][commit_metric] for idx in commit_ids]\n",
    "    if period_metric == 'avg':\n",
    "        return np.mean(period_commit_centrality)\n",
    "    elif period_metric == 'max':\n",
    "        return np.max(period_commit_centrality)\n",
    "    elif period_metric == 'median':\n",
    "        return np.median(period_commit_centrality)\n",
    "    elif period_metric == 'sum':\n",
    "        return np.sum(period_commit_centrality)\n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "867ecedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(projects)):\n",
    "    proj = projects[i]\n",
    "    dev_commits_dict = project_commit_df[i].groupby(['Author']).apply(lambda x: list(x.index)).to_dict()\n",
    "    filtered_developer_period_df.loc[filtered_developer_period_df['project']==proj, 'period commit centrality'] = filtered_developer_period_df.loc[filtered_developer_period_df['project']==proj].apply(\n",
    "        lambda x:period_centrality(x, dev_commits_dict[x['name']], project_commits[i], 'avg', 'sum'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7296d1f",
   "metadata": {},
   "source": [
    "## Store extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbb047",
   "metadata": {},
   "source": [
    "### Sort each developer's activities in periods into a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f28abfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_periods_to_sequence(proj, name, feature_name):\n",
    "    df = filtered_developer_period_df.loc[(filtered_developer_period_df['project']==proj)&(filtered_developer_period_df['name']==name)]\n",
    "    if len(df) == 1:\n",
    "        return df[feature_name].to_list()\n",
    "    elif len(df) == 0:\n",
    "        return None\n",
    "    seq_dict = pd.Series(df[feature_name].values, index=df['period']).to_dict()\n",
    "    seq_dict = dict(sorted(seq_dict.items()))\n",
    "    seq = list(seq_dict.values())\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_sequence = developer_data[['name', 'project','profile', 'join date']]\n",
    "developer_sequence['workload_sequence'] = developer_sequence.apply(lambda x:bin_periods_to_sequence(x['project'],x['name'], 'wcp_code'),axis=1)\n",
    "developer_sequence = developer_sequence.loc[~developer_sequence['workload_sequence'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ceef3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin period work preference into sequence\n",
    "for fea in work_preference_features:\n",
    "    developer_sequence[f'{fea}_sequence'] = developer_sequence.apply(lambda x:bin_periods_to_sequence(x['project'],x['name'], fea),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb2c0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin period work preference into sequence\n",
    "for fea in features:\n",
    "    developer_sequence[f'{fea}_sequence'] = developer_sequence.apply(lambda x:bin_periods_to_sequence(x['project'],x['name'], fea),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b062dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin period technical importance into sequence\n",
    "fea = 'period commit centrality'\n",
    "developer_sequence[f'{fea}_sequence'] = developer_sequence.apply(lambda x:bin_periods_to_sequence(x['project'],x['name'], fea),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3c3846cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin per commit importance into sequence\n",
    "def get_per_commit_centrality_sequence(commit_ids, commit_dict, commit_metric = 'avg'):\n",
    "    if len(commit_ids) <= 0:\n",
    "        return 0\n",
    "    commit_metric = commit_metric +' centrality'\n",
    "    commit_ids = sorted(commit_ids, key=lambda x:commit_dict[x]['Time'])\n",
    "\n",
    "    return [commit_dict[idx][commit_metric] for idx in commit_ids]\n",
    "\n",
    "for i in range(len(projects)):\n",
    "    proj = projects[i]\n",
    "    dev_commits_dict = project_commit_df[i].groupby(['Author']).apply(lambda x: list(x.index)).to_dict()\n",
    "    developer_sequence.loc[developer_sequence['project']==proj, 'per commit centrality_sequence'] = developer_sequence.loc[developer_sequence['project']==proj]['name'].apply(\n",
    "        lambda x:get_per_commit_centrality_sequence(dev_commits_dict[x], project_commits[i], 'avg')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109a3c4",
   "metadata": {},
   "source": [
    "### calculate technical importance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f19cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_centrality_day(row, commit_ids, commit_dict, commit_metric = 'avg'):\n",
    "    commit_metric = commit_metric +' centrality'\n",
    "    max_commit_id = max(commit_ids, key=lambda x:commit_dict[x][commit_metric])\n",
    "    return (commit_dict[max_commit_id]['Time'] - row['join date']).days\n",
    "\n",
    "\n",
    "developer_sequence['max_commit_centrality'] = developer_sequence['per commit centrality_sequence'].apply(max)\n",
    "developer_sequence['max_period_centrality'] = developer_sequence['period commit centrality_sequence'].apply(max)\n",
    "developer_sequence['max_centrality_period'] = developer_sequence['period commit centrality_sequence'].apply(lambda x: np.argmax(x)+1)\n",
    "for i in range(len(projects)):\n",
    "    proj = projects[i]\n",
    "    dev_commits_dict = project_commit_df[i].groupby(['Author']).apply(lambda x: list(x.index)).to_dict()\n",
    "    developer_sequence.loc[developer_sequence['project']==proj, 'max_centrality_day'] = developer_sequence.loc[developer_sequence['project']==proj].apply(\n",
    "        lambda x:get_max_centrality_day(x, dev_commits_dict[x['name']], project_commits[i], 'avg'), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ccd58",
   "metadata": {},
   "source": [
    "### store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf1bb7a5-3b05-4241-a1f9-96dcdc1f8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_developer_period_df.to_csv(os.path.join(basedir,'contributor_period_activity.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "edbe2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_sequence.to_csv(os.path.join(basedir,'contributor_activity_sequence.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f2a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
